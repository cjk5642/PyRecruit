<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>recruits.ncaaf.player API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>recruits.ncaaf.player</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from bs4 import BeautifulSoup
import pandas as pd
import requests
from tqdm import tqdm
from .utils import HEADERS, Ratings247, CollegeRecruitingInterest, Evaluators, Connections, Expert
from .datamodels import PlayerDC

class Players:
    players = None
    def __init__(self, 
                 year:int = None, 
                 institution:str = &#34;HighSchool&#34;, 
                 pos:str = None, 
                 composite_rankings:bool = True, 
                 state:str = None,
                 top:int = 1000,
                 in_depth: bool = False):

        self.year = 2022 if not year else year
        self.institution = institution
        self.pos = self._check_position(pos) if pos else None
        self.top = top
        self.composite_rankings = composite_rankings
        self.state = state
        self.in_depth = in_depth
        self.url = self._create_url()
        self.html_players = self._parse_players()

    def _check_position(self, pos:str):
        positions = [&#34;QB&#34;, &#34;RB&#34;, &#34;WR&#34;, &#34;TE&#34;, &#34;OT&#34;, &#34;IOL&#34;, &#34;EDGE&#34;, &#34;DL&#34;, &#34;LB&#34;, &#34;CB&#34;, &#34;S&#34;, &#34;ATH&#34;, &#34;K&#34;, &#34;P&#34;, &#34;LS&#34;, &#34;RET&#34;]
        joined_pos = &#39;, &#39;.join(positions)
        pos = pos.upper()
        if pos not in positions:
            raise ValueError(f&#34;Position &#39;{pos}&#39; is not a valid position. Please use one of the following:\n[{joined_pos}]&#34;)
        return pos

    def _create_url(self):
        base_url = &#34;https://247sports.com/Season/&#34;
        year_part = f&#34;{self.year}-Football/&#34;
        rankings_part = &#34;CompositeRecruitRankings/?&#34; if self.composite_rankings else &#34;RecruitRankings/?&#34;
        
        # queries
        institution_part = f&#34;InstitutionGroup={self.institution}&#34;

        # join the strings for url
        join_base_str = base_url + year_part + rankings_part + institution_part

        # check if any additional patterns are matched
        if self.pos:
            join_base_str += f&#34;&amp;PositionGroup={self.pos}&#34;
        
        if self.state:
            join_base_str += f&#34;&amp;State={self.state}&#34;

        return join_base_str

    def _parse_players(self):
        all_players = []
        print(&#34;Parsing players...&#34;)
        new_url = self.url + f&#34;&amp;Page=1&#34;
        page = requests.get(new_url, headers = HEADERS)
        soup = BeautifulSoup(page.content, &#34;html.parser&#34;)
        players = soup.findAll(&#34;li&#34;, class_ = &#34;rankings-page__list-item&#34;)[:-1]
        players = [p.find(&#39;div&#39;, class_ = &#34;wrapper&#34;) for p in players]
        all_players.extend(players)

        num_players = len(players)
        i = 2
        pbar = tqdm(total = self.top - num_players)
        while num_players &lt; self.top:
            new_url = self.url + f&#34;&amp;Page={i}&#34;
            page = requests.get(new_url, headers = HEADERS)
            soup = BeautifulSoup(page.content, &#34;html.parser&#34;)
            players = soup.findAll(&#34;li&#34;, class_ = &#34;rankings-page__list-item&#34;)[:-1]
            for p in players:
                p = p.find(&#39;div&#39;, class_ = &#34;wrapper&#34;)
                if num_players &lt; self.top:
                    num_players += 1
                    pbar.update(1)
                    all_players.append(p)
                else:
                    break
            i += 1
        return all_players

    def _get_ranking(self, player: str):
        try:
            ranking = player.find(&#39;div&#39;, class_ = &#34;rank-column&#34;)
            primary = ranking.find(&#39;div&#39;, class_ = &#34;primary&#34;).text.replace(&#34;\n&#34;, &#34;&#34;).replace(&#34; &#34;, &#34;&#34;)
            other = ranking.find(&#34;div&#34;, class_ = &#34;other&#34;).text.replace(&#34;\n&#34;, &#34;&#34;).replace(&#34; &#34;, &#34;&#34;)
            return primary, other
        except (ValueError, AttributeError):
            return None, None

    def _get_recruit(self, player: str):
        try:
            recruit = player.find(&#39;div&#39;, class_ = &#34;recruit&#34;)
            recruit_meta = recruit.find(&#34;a&#34;, class_ = &#34;rankings-page__name-link&#34;)
            recruit_link = recruit_meta[&#39;href&#39;]
            recruit_name = recruit_meta.text.replace(&#34; \n&#34;, &#34;&#34;).strip()

            recruit_location = recruit.find(&#34;span&#34;, class_ = &#34;meta&#34;).text.replace(&#34;\n&#34;, &#34;&#34;).strip()
            recruit_location = &#34; &#34;.join(recruit_location.split())
            return recruit_link, recruit_name, recruit_location
        except AttributeError:
            return None, None, None

    def _get_position(self, player: str):
        try:
            return player.find(&#34;div&#34;, class_ = &#39;position&#39;).text.replace(&#34;\n&#34;, &#34;&#34;).replace(&#34; &#34;, &#34;&#34;)
        except AttributeError:
            return None

    def _get_metrics(self, player: str):
        try:
            metrics = player.find(&#34;div&#34;, class_ = &#34;metrics&#34;).text
            return &#34; &#34;.join(metrics.split())
        except AttributeError:
            return None

    def _get_ratings(self, player: str):
        try:
            ratings = player.find(&#34;div&#34;, class_ = &#34;rating&#34;)
            score = ratings.find(&#34;div&#34;, class_ = &#34;rankings-page__star-and-score&#34;)
            score = score.find(&#34;span&#34;, class_ = &#34;score&#34;).text

            rank = ratings.find(&#34;div&#34;, class_ = &#34;rank&#34;)
            national_rank = rank.find(&#34;a&#34;, class_ = &#34;natrank&#34;).text.replace(&#34;\n&#34;, &#34;&#34;).replace(&#34; &#34;, &#34;&#34;)
            position_rank = rank.find(&#34;a&#34;, class_ = &#34;posrank&#34;).text.replace(&#34;\n&#34;, &#34;&#34;).replace(&#34; &#34;, &#34;&#34;)
            state_rank = rank.find(&#34;a&#34;, class_ = &#34;sttrank&#34;).text.replace(&#34;\n&#34;, &#34;&#34;).replace(&#34; &#34;, &#34;&#34;)
            return national_rank, position_rank, state_rank
        except AttributeError:
            return None, None, None


    def _get_status(self, player:str):
        try:
            status = player.find(&#34;div&#34;, class_ = &#34;status&#34;)
        except AttributeError:
            return None, None

        # if player is commited to team
        try: 
            team = status.find(&#34;a&#34;, class_ = &#34;img-link&#34;).find(&#34;img&#34;)[&#39;alt&#39;]
            return team, None
        except:
            pass

        # if player is not committed or almost committed
        team_helper = status.find(&#34;div&#34;, class_ = &#34;rankings-page__crystal-ball&#34;).find(&#34;div&#34;, class_ = &#34;cb-block&#34;)
        try:
            team = team_helper.find(&#34;img&#34;)[&#39;alt&#39;]
            percentage = team_helper.find(&#34;span&#34;, class_ = &#34;percentage&#34;).text.strip()
            return team, percentage
        
        except:
            return None, None
    @property
    def get_players(self):
        players = []
        for player in tqdm(self.html_players):
            p_dict = {}
            p_dict[&#39;primary_ranking&#39;], p_dict[&#39;other_ranking&#39;] = self._get_ranking(player)
            p_dict[&#39;recruit_link&#39;], p_dict[&#39;recruit_name&#39;], p_dict[&#39;recruit_location&#39;] = self._get_recruit(player)
            p_dict[&#39;position&#39;] = self._get_position(player)
            p_dict[&#39;metrics&#39;] = self._get_metrics(player)
            p_dict[&#39;national_rank&#39;], p_dict[&#39;position_rank&#39;], p_dict[&#39;state_rank&#39;] = self._get_ratings(player)
            p_dict[&#39;commited_team&#39;], p_dict[&#39;commited_team_percentage&#39;] = self._get_status(player)
            players.append(p_dict)
        # cache player list in class
        Players.players = players
        return players 

    @property
    def to_df(self):
        if Players.players is None:
            Players.players = self.get_players
        
        return pd.DataFrame.from_dict(Players.players)

class Player:
    def __init__(self, name_id:str):
        &#34;&#34;&#34;name_id found from 247 sports player page like Travis-Hunter-46084728&#34;&#34;&#34;
        self.name_id = name_id
        self.url = f&#34;https://247sports.com/Player/{self.name_id}/&#34;

    def _get_page(self, url: str):
        if not url.startswith(&#34;https:&#34;):
            url = &#34;https:&#34; + url
        page = requests.get(url, headers=HEADERS)
        soup = BeautifulSoup(page.content, &#34;html.parser&#34;)
        return soup

    @property  
    def player(self):
        soup = self._get_page(self.url)

        # determine if older or current recruit
        as_a_prospect = soup.find(&#34;section&#34;, class_=&#34;as-a-prospect&#34;)
        if as_a_prospect:
            profile_link = as_a_prospect.find(&#34;a&#34;, class_=&#39;view-profile-link&#39;)[&#39;href&#39;]
            soup = self._get_page(profile_link)

        print(&#34;Recruit name...&#34;)
        recruit_name = soup.find(&#34;h1&#34;, class_ = &#34;name&#34;).text 

        # find metrics
        print(&#34;Getting metrics...&#34;)
        metrics = self._find_metrics(soup)

        # find details
        print(&#34;Getting details...&#34;)
        details = self._find_details(soup)
        
        # get rankings
        print(&#34;Getting rankings...&#34;)
        ratings_data = Ratings247(soup, metrics[&#39;pos&#39;], details[&#39;state&#39;]).ratings

        # get expert predictions
        print(&#34;Getting predictions...&#34;)
        experts = self._find_predictions(soup)

        # get college interest
        print(&#34;Getting College Interests...&#34;)
        college_interest = CollegeRecruitingInterest(soup).college_interest

        # get accolades
        print(&#34;Getting Accolades...&#34;)
        accolades = self._find_accolades(soup)

        # get evaluators, background and skills
        print(&#34;Getting Evaluators, Background, and Skills...&#34;)
        evaluators, background, skills = Evaluators(soup).evaluator

        # get stats
        print(&#34;Getting stats...&#34;)
        stats = self._find_stats(soup)

        # get Connections
        print(&#34;Getting Connections...&#34;)
        connections = Connections(soup).connections

        return PlayerDC(
            name_id = self.name_id, 
            url = self.url, 
            recruit_name = recruit_name, 
            experts = experts, 
            college_interest = college_interest,
            accolades = accolades,
            evaluators = evaluators,
            background = background, 
            skills = skills, 
            stats = stats,
            connections = connections,
            ratings=ratings_data,
            **metrics,
            **details
        )

    def _find_metrics(self, soup_page):
        data = {}
        metrics = soup_page.find(&#34;ul&#34;, class_ = &#34;metrics-list&#34;).find_all(&#34;li&#34;)
        for m in metrics:
            spans =  m.find_all(&#34;span&#34;)
            if spans[0].text == &#39;Pos&#39;:
                data[&#39;pos&#39;] = spans[1].text
            if spans[0].text == &#34;Height&#34;:
                data[&#39;height&#39;] = spans[1].text
            if spans[0].text == &#39;Weight&#39;:
                data[&#39;weight&#39;] = int(spans[1].text)
        return data

    def _find_details(self, soup_page):
        details = soup_page.find(&#34;ul&#34;, class_ = &#34;details&#34;).find_all(&#34;li&#34;)
        data = {}
        for d in details:
            spans = d.find_all(&#34;span&#34;)
            if spans[0].text == &#39;High School&#39;:
                data[&#39;high_school&#39;] = spans[1].find(&#34;a&#34;).text.strip()
            elif spans[0].text == &#39;City&#39;:
                data[&#39;city&#39;], data[&#39;state&#39;] = spans[1].text.strip().split(&#34;, &#34;)
            elif spans[0].text.lower().strip() == &#34;class&#34;:
                data[&#39;class_year&#39;] = int(spans[1].text.strip())
        return data

    def _get_expert_averages(self, soup):
        expert_averages = soup.find(&#34;ul&#34;, class_ = &#34;prediction-list long&#34;)
        if not expert_averages:
            return None

        list_ea = expert_averages.find_all(&#39;li&#39;)[1:]
        list_ea_dict = {}
        for lea in list_ea:
            link = lea.find(&#39;a&#39;).find(&#39;img&#39;, class_ = &#39;team-image&#39;)[&#39;src&#39;]
            name = lea.find(&#34;span&#34;).text
            list_ea_dict[link] = name
        return list_ea_dict

    def _get_extended_predictions(self, url:str):
        soup = self._get_page(url)
        lead_experts = soup.find(&#34;ul&#34;, class_=&#39;cb-list no-border&#39;).find_all(&#39;li&#39;)
        other_experts = soup.find(&#34;ul&#34;, class_=&#39;cb-list no-margin&#39;).find_all(&#39;li&#39;)
        total_experts = lead_experts + other_experts
        expert_list = []
        for expert in total_experts:

            # get name and title
            exp = expert.find(&#34;div&#34;, class_=&#39;name&#39;)
            name = exp.find(&#34;a&#34;).text.strip()
            title = exp.find_all(&#34;span&#34;)[-1].text.strip()

            # get accuracy for this year
            acc_year = expert.find(&#34;div&#34;, class_=&#34;accuracy year&#34;).find_all(&#39;span&#39;)[-1].text
            acc_year = float(acc_year.translate(str.maketrans(&#34;&#34;, &#34;&#34;, &#34;()\%&#34;))) / 100

            # get accuracy for all time
            acc_all = expert.find(&#34;div&#34;, class_=&#34;accuracy all-time&#34;).find_all(&#39;span&#39;)[-1].text
            acc_all = float(acc_all.translate(str.maketrans(&#34;&#34;, &#34;&#34;, &#34;()\%&#34;))) / 100

            # get prediction
            prediction = expert.find(&#39;div&#39;, class_=&#39;prediction&#39;)
            pred = prediction.find(&#34;img&#34;)[&#39;alt&#39;]
            pred_date = prediction.find(&#34;div&#34;, class_=&#39;date-time&#39;)
            if pred_date:
                date_time = &#39; &#39;.join([tag.text.strip() for tag in pred_date.find_all(&#34;span&#34;)])
            else:
                date_time = None

            # get expert score
            score = expert.find(&#34;div&#34;, class_=&#39;confidence&#39;)
            expert_score = int(score.find(&#34;div&#34;, class_=&#34;confidence-wrap&#34;).find(&#34;b&#34;).text.strip())


            new_exp = Expert(
                name = name, title = title, accuracy_year=acc_year, 
                accuracy_all_time=acc_all, prediction=pred, 
                prediction_datetime=date_time, expert_score=expert_score
            )

            expert_list.append(new_exp)
        return expert_list

    def _find_predictions(self, soup):
        experts = soup.find(&#34;ul&#34;, class_ = &#34;prediction-list long expert&#34;)
        if not experts:
            return None
        
        # see if there are extended experts 
        link_block = soup.find(&#34;ul&#34;, class_=&#39;link-block&#39;)
        if link_block:
            link = link_block.find(&#39;a&#39;)[&#39;href&#39;]
            return self._get_extended_predictions(link)

        img_conversion = self._get_expert_averages(soup)
        if img_conversion:
            lead_experts = experts.find_all(&#34;li&#34;)[1:]
            lead_experts_list = []
            for i, expert in enumerate(lead_experts):
                expert_name = expert.find(&#39;a&#39;, class_=&#39;expert-link&#39;).text
                score = expert.find(&#39;b&#39;, class_ = &#34;confidence-score lock&#34;).text
                college = img_conversion[expert.find(&#39;img&#39;)[&#39;src&#39;]]
                expert = Expert(name=expert_name, expert_score=score, prediction=college)
                lead_experts_list.append(expert)
            return lead_experts_list[0] if len(lead_experts_list) == 0 else lead_experts_list
        


    def _find_accolades(self, soup):
        accolades = soup.find(&#39;section&#39;, class_ = &#39;accolades&#39;)
        if not accolades:
            return None
        
        accolades_list = accolades.find(&#34;ul&#34;).find_all(&#34;li&#34;)
        accolades_final = [accolade.find(&#39;a&#39;, class_=&#39;event-link&#39;).text for i, accolade in enumerate(accolades_list)]
        return accolades_final
        
    def _find_stats(self, soup):
        stats = soup.find(&#39;section&#39;, class_=&#34;profile-stats&#34;)
        if not stats:
            return None

        left_table_html = str(stats.find(&#34;table&#34;, class_=&#39;left-table&#39;))
        right_table_html = str(stats.find(&#39;table&#39;, class_=&#39;right-table&#39;))
        left_table = pd.read_html(left_table_html)[0]
        right_table = pd.read_html(right_table_html)[0]
        total = pd.concat([left_table, right_table], axis = 1)
        return total</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="recruits.ncaaf.player.Player"><code class="flex name class">
<span>class <span class="ident">Player</span></span>
<span>(</span><span>name_id: str)</span>
</code></dt>
<dd>
<div class="desc"><p>name_id found from 247 sports player page like Travis-Hunter-46084728</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Player:
    def __init__(self, name_id:str):
        &#34;&#34;&#34;name_id found from 247 sports player page like Travis-Hunter-46084728&#34;&#34;&#34;
        self.name_id = name_id
        self.url = f&#34;https://247sports.com/Player/{self.name_id}/&#34;

    def _get_page(self, url: str):
        if not url.startswith(&#34;https:&#34;):
            url = &#34;https:&#34; + url
        page = requests.get(url, headers=HEADERS)
        soup = BeautifulSoup(page.content, &#34;html.parser&#34;)
        return soup

    @property  
    def player(self):
        soup = self._get_page(self.url)

        # determine if older or current recruit
        as_a_prospect = soup.find(&#34;section&#34;, class_=&#34;as-a-prospect&#34;)
        if as_a_prospect:
            profile_link = as_a_prospect.find(&#34;a&#34;, class_=&#39;view-profile-link&#39;)[&#39;href&#39;]
            soup = self._get_page(profile_link)

        print(&#34;Recruit name...&#34;)
        recruit_name = soup.find(&#34;h1&#34;, class_ = &#34;name&#34;).text 

        # find metrics
        print(&#34;Getting metrics...&#34;)
        metrics = self._find_metrics(soup)

        # find details
        print(&#34;Getting details...&#34;)
        details = self._find_details(soup)
        
        # get rankings
        print(&#34;Getting rankings...&#34;)
        ratings_data = Ratings247(soup, metrics[&#39;pos&#39;], details[&#39;state&#39;]).ratings

        # get expert predictions
        print(&#34;Getting predictions...&#34;)
        experts = self._find_predictions(soup)

        # get college interest
        print(&#34;Getting College Interests...&#34;)
        college_interest = CollegeRecruitingInterest(soup).college_interest

        # get accolades
        print(&#34;Getting Accolades...&#34;)
        accolades = self._find_accolades(soup)

        # get evaluators, background and skills
        print(&#34;Getting Evaluators, Background, and Skills...&#34;)
        evaluators, background, skills = Evaluators(soup).evaluator

        # get stats
        print(&#34;Getting stats...&#34;)
        stats = self._find_stats(soup)

        # get Connections
        print(&#34;Getting Connections...&#34;)
        connections = Connections(soup).connections

        return PlayerDC(
            name_id = self.name_id, 
            url = self.url, 
            recruit_name = recruit_name, 
            experts = experts, 
            college_interest = college_interest,
            accolades = accolades,
            evaluators = evaluators,
            background = background, 
            skills = skills, 
            stats = stats,
            connections = connections,
            ratings=ratings_data,
            **metrics,
            **details
        )

    def _find_metrics(self, soup_page):
        data = {}
        metrics = soup_page.find(&#34;ul&#34;, class_ = &#34;metrics-list&#34;).find_all(&#34;li&#34;)
        for m in metrics:
            spans =  m.find_all(&#34;span&#34;)
            if spans[0].text == &#39;Pos&#39;:
                data[&#39;pos&#39;] = spans[1].text
            if spans[0].text == &#34;Height&#34;:
                data[&#39;height&#39;] = spans[1].text
            if spans[0].text == &#39;Weight&#39;:
                data[&#39;weight&#39;] = int(spans[1].text)
        return data

    def _find_details(self, soup_page):
        details = soup_page.find(&#34;ul&#34;, class_ = &#34;details&#34;).find_all(&#34;li&#34;)
        data = {}
        for d in details:
            spans = d.find_all(&#34;span&#34;)
            if spans[0].text == &#39;High School&#39;:
                data[&#39;high_school&#39;] = spans[1].find(&#34;a&#34;).text.strip()
            elif spans[0].text == &#39;City&#39;:
                data[&#39;city&#39;], data[&#39;state&#39;] = spans[1].text.strip().split(&#34;, &#34;)
            elif spans[0].text.lower().strip() == &#34;class&#34;:
                data[&#39;class_year&#39;] = int(spans[1].text.strip())
        return data

    def _get_expert_averages(self, soup):
        expert_averages = soup.find(&#34;ul&#34;, class_ = &#34;prediction-list long&#34;)
        if not expert_averages:
            return None

        list_ea = expert_averages.find_all(&#39;li&#39;)[1:]
        list_ea_dict = {}
        for lea in list_ea:
            link = lea.find(&#39;a&#39;).find(&#39;img&#39;, class_ = &#39;team-image&#39;)[&#39;src&#39;]
            name = lea.find(&#34;span&#34;).text
            list_ea_dict[link] = name
        return list_ea_dict

    def _get_extended_predictions(self, url:str):
        soup = self._get_page(url)
        lead_experts = soup.find(&#34;ul&#34;, class_=&#39;cb-list no-border&#39;).find_all(&#39;li&#39;)
        other_experts = soup.find(&#34;ul&#34;, class_=&#39;cb-list no-margin&#39;).find_all(&#39;li&#39;)
        total_experts = lead_experts + other_experts
        expert_list = []
        for expert in total_experts:

            # get name and title
            exp = expert.find(&#34;div&#34;, class_=&#39;name&#39;)
            name = exp.find(&#34;a&#34;).text.strip()
            title = exp.find_all(&#34;span&#34;)[-1].text.strip()

            # get accuracy for this year
            acc_year = expert.find(&#34;div&#34;, class_=&#34;accuracy year&#34;).find_all(&#39;span&#39;)[-1].text
            acc_year = float(acc_year.translate(str.maketrans(&#34;&#34;, &#34;&#34;, &#34;()\%&#34;))) / 100

            # get accuracy for all time
            acc_all = expert.find(&#34;div&#34;, class_=&#34;accuracy all-time&#34;).find_all(&#39;span&#39;)[-1].text
            acc_all = float(acc_all.translate(str.maketrans(&#34;&#34;, &#34;&#34;, &#34;()\%&#34;))) / 100

            # get prediction
            prediction = expert.find(&#39;div&#39;, class_=&#39;prediction&#39;)
            pred = prediction.find(&#34;img&#34;)[&#39;alt&#39;]
            pred_date = prediction.find(&#34;div&#34;, class_=&#39;date-time&#39;)
            if pred_date:
                date_time = &#39; &#39;.join([tag.text.strip() for tag in pred_date.find_all(&#34;span&#34;)])
            else:
                date_time = None

            # get expert score
            score = expert.find(&#34;div&#34;, class_=&#39;confidence&#39;)
            expert_score = int(score.find(&#34;div&#34;, class_=&#34;confidence-wrap&#34;).find(&#34;b&#34;).text.strip())


            new_exp = Expert(
                name = name, title = title, accuracy_year=acc_year, 
                accuracy_all_time=acc_all, prediction=pred, 
                prediction_datetime=date_time, expert_score=expert_score
            )

            expert_list.append(new_exp)
        return expert_list

    def _find_predictions(self, soup):
        experts = soup.find(&#34;ul&#34;, class_ = &#34;prediction-list long expert&#34;)
        if not experts:
            return None
        
        # see if there are extended experts 
        link_block = soup.find(&#34;ul&#34;, class_=&#39;link-block&#39;)
        if link_block:
            link = link_block.find(&#39;a&#39;)[&#39;href&#39;]
            return self._get_extended_predictions(link)

        img_conversion = self._get_expert_averages(soup)
        if img_conversion:
            lead_experts = experts.find_all(&#34;li&#34;)[1:]
            lead_experts_list = []
            for i, expert in enumerate(lead_experts):
                expert_name = expert.find(&#39;a&#39;, class_=&#39;expert-link&#39;).text
                score = expert.find(&#39;b&#39;, class_ = &#34;confidence-score lock&#34;).text
                college = img_conversion[expert.find(&#39;img&#39;)[&#39;src&#39;]]
                expert = Expert(name=expert_name, expert_score=score, prediction=college)
                lead_experts_list.append(expert)
            return lead_experts_list[0] if len(lead_experts_list) == 0 else lead_experts_list
        


    def _find_accolades(self, soup):
        accolades = soup.find(&#39;section&#39;, class_ = &#39;accolades&#39;)
        if not accolades:
            return None
        
        accolades_list = accolades.find(&#34;ul&#34;).find_all(&#34;li&#34;)
        accolades_final = [accolade.find(&#39;a&#39;, class_=&#39;event-link&#39;).text for i, accolade in enumerate(accolades_list)]
        return accolades_final
        
    def _find_stats(self, soup):
        stats = soup.find(&#39;section&#39;, class_=&#34;profile-stats&#34;)
        if not stats:
            return None

        left_table_html = str(stats.find(&#34;table&#34;, class_=&#39;left-table&#39;))
        right_table_html = str(stats.find(&#39;table&#39;, class_=&#39;right-table&#39;))
        left_table = pd.read_html(left_table_html)[0]
        right_table = pd.read_html(right_table_html)[0]
        total = pd.concat([left_table, right_table], axis = 1)
        return total</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="recruits.ncaaf.player.Player.player"><code class="name">var <span class="ident">player</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property  
def player(self):
    soup = self._get_page(self.url)

    # determine if older or current recruit
    as_a_prospect = soup.find(&#34;section&#34;, class_=&#34;as-a-prospect&#34;)
    if as_a_prospect:
        profile_link = as_a_prospect.find(&#34;a&#34;, class_=&#39;view-profile-link&#39;)[&#39;href&#39;]
        soup = self._get_page(profile_link)

    print(&#34;Recruit name...&#34;)
    recruit_name = soup.find(&#34;h1&#34;, class_ = &#34;name&#34;).text 

    # find metrics
    print(&#34;Getting metrics...&#34;)
    metrics = self._find_metrics(soup)

    # find details
    print(&#34;Getting details...&#34;)
    details = self._find_details(soup)
    
    # get rankings
    print(&#34;Getting rankings...&#34;)
    ratings_data = Ratings247(soup, metrics[&#39;pos&#39;], details[&#39;state&#39;]).ratings

    # get expert predictions
    print(&#34;Getting predictions...&#34;)
    experts = self._find_predictions(soup)

    # get college interest
    print(&#34;Getting College Interests...&#34;)
    college_interest = CollegeRecruitingInterest(soup).college_interest

    # get accolades
    print(&#34;Getting Accolades...&#34;)
    accolades = self._find_accolades(soup)

    # get evaluators, background and skills
    print(&#34;Getting Evaluators, Background, and Skills...&#34;)
    evaluators, background, skills = Evaluators(soup).evaluator

    # get stats
    print(&#34;Getting stats...&#34;)
    stats = self._find_stats(soup)

    # get Connections
    print(&#34;Getting Connections...&#34;)
    connections = Connections(soup).connections

    return PlayerDC(
        name_id = self.name_id, 
        url = self.url, 
        recruit_name = recruit_name, 
        experts = experts, 
        college_interest = college_interest,
        accolades = accolades,
        evaluators = evaluators,
        background = background, 
        skills = skills, 
        stats = stats,
        connections = connections,
        ratings=ratings_data,
        **metrics,
        **details
    )</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="recruits.ncaaf.player.Players"><code class="flex name class">
<span>class <span class="ident">Players</span></span>
<span>(</span><span>year: int = None, institution: str = 'HighSchool', pos: str = None, composite_rankings: bool = True, state: str = None, top: int = 1000, in_depth: bool = False)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Players:
    players = None
    def __init__(self, 
                 year:int = None, 
                 institution:str = &#34;HighSchool&#34;, 
                 pos:str = None, 
                 composite_rankings:bool = True, 
                 state:str = None,
                 top:int = 1000,
                 in_depth: bool = False):

        self.year = 2022 if not year else year
        self.institution = institution
        self.pos = self._check_position(pos) if pos else None
        self.top = top
        self.composite_rankings = composite_rankings
        self.state = state
        self.in_depth = in_depth
        self.url = self._create_url()
        self.html_players = self._parse_players()

    def _check_position(self, pos:str):
        positions = [&#34;QB&#34;, &#34;RB&#34;, &#34;WR&#34;, &#34;TE&#34;, &#34;OT&#34;, &#34;IOL&#34;, &#34;EDGE&#34;, &#34;DL&#34;, &#34;LB&#34;, &#34;CB&#34;, &#34;S&#34;, &#34;ATH&#34;, &#34;K&#34;, &#34;P&#34;, &#34;LS&#34;, &#34;RET&#34;]
        joined_pos = &#39;, &#39;.join(positions)
        pos = pos.upper()
        if pos not in positions:
            raise ValueError(f&#34;Position &#39;{pos}&#39; is not a valid position. Please use one of the following:\n[{joined_pos}]&#34;)
        return pos

    def _create_url(self):
        base_url = &#34;https://247sports.com/Season/&#34;
        year_part = f&#34;{self.year}-Football/&#34;
        rankings_part = &#34;CompositeRecruitRankings/?&#34; if self.composite_rankings else &#34;RecruitRankings/?&#34;
        
        # queries
        institution_part = f&#34;InstitutionGroup={self.institution}&#34;

        # join the strings for url
        join_base_str = base_url + year_part + rankings_part + institution_part

        # check if any additional patterns are matched
        if self.pos:
            join_base_str += f&#34;&amp;PositionGroup={self.pos}&#34;
        
        if self.state:
            join_base_str += f&#34;&amp;State={self.state}&#34;

        return join_base_str

    def _parse_players(self):
        all_players = []
        print(&#34;Parsing players...&#34;)
        new_url = self.url + f&#34;&amp;Page=1&#34;
        page = requests.get(new_url, headers = HEADERS)
        soup = BeautifulSoup(page.content, &#34;html.parser&#34;)
        players = soup.findAll(&#34;li&#34;, class_ = &#34;rankings-page__list-item&#34;)[:-1]
        players = [p.find(&#39;div&#39;, class_ = &#34;wrapper&#34;) for p in players]
        all_players.extend(players)

        num_players = len(players)
        i = 2
        pbar = tqdm(total = self.top - num_players)
        while num_players &lt; self.top:
            new_url = self.url + f&#34;&amp;Page={i}&#34;
            page = requests.get(new_url, headers = HEADERS)
            soup = BeautifulSoup(page.content, &#34;html.parser&#34;)
            players = soup.findAll(&#34;li&#34;, class_ = &#34;rankings-page__list-item&#34;)[:-1]
            for p in players:
                p = p.find(&#39;div&#39;, class_ = &#34;wrapper&#34;)
                if num_players &lt; self.top:
                    num_players += 1
                    pbar.update(1)
                    all_players.append(p)
                else:
                    break
            i += 1
        return all_players

    def _get_ranking(self, player: str):
        try:
            ranking = player.find(&#39;div&#39;, class_ = &#34;rank-column&#34;)
            primary = ranking.find(&#39;div&#39;, class_ = &#34;primary&#34;).text.replace(&#34;\n&#34;, &#34;&#34;).replace(&#34; &#34;, &#34;&#34;)
            other = ranking.find(&#34;div&#34;, class_ = &#34;other&#34;).text.replace(&#34;\n&#34;, &#34;&#34;).replace(&#34; &#34;, &#34;&#34;)
            return primary, other
        except (ValueError, AttributeError):
            return None, None

    def _get_recruit(self, player: str):
        try:
            recruit = player.find(&#39;div&#39;, class_ = &#34;recruit&#34;)
            recruit_meta = recruit.find(&#34;a&#34;, class_ = &#34;rankings-page__name-link&#34;)
            recruit_link = recruit_meta[&#39;href&#39;]
            recruit_name = recruit_meta.text.replace(&#34; \n&#34;, &#34;&#34;).strip()

            recruit_location = recruit.find(&#34;span&#34;, class_ = &#34;meta&#34;).text.replace(&#34;\n&#34;, &#34;&#34;).strip()
            recruit_location = &#34; &#34;.join(recruit_location.split())
            return recruit_link, recruit_name, recruit_location
        except AttributeError:
            return None, None, None

    def _get_position(self, player: str):
        try:
            return player.find(&#34;div&#34;, class_ = &#39;position&#39;).text.replace(&#34;\n&#34;, &#34;&#34;).replace(&#34; &#34;, &#34;&#34;)
        except AttributeError:
            return None

    def _get_metrics(self, player: str):
        try:
            metrics = player.find(&#34;div&#34;, class_ = &#34;metrics&#34;).text
            return &#34; &#34;.join(metrics.split())
        except AttributeError:
            return None

    def _get_ratings(self, player: str):
        try:
            ratings = player.find(&#34;div&#34;, class_ = &#34;rating&#34;)
            score = ratings.find(&#34;div&#34;, class_ = &#34;rankings-page__star-and-score&#34;)
            score = score.find(&#34;span&#34;, class_ = &#34;score&#34;).text

            rank = ratings.find(&#34;div&#34;, class_ = &#34;rank&#34;)
            national_rank = rank.find(&#34;a&#34;, class_ = &#34;natrank&#34;).text.replace(&#34;\n&#34;, &#34;&#34;).replace(&#34; &#34;, &#34;&#34;)
            position_rank = rank.find(&#34;a&#34;, class_ = &#34;posrank&#34;).text.replace(&#34;\n&#34;, &#34;&#34;).replace(&#34; &#34;, &#34;&#34;)
            state_rank = rank.find(&#34;a&#34;, class_ = &#34;sttrank&#34;).text.replace(&#34;\n&#34;, &#34;&#34;).replace(&#34; &#34;, &#34;&#34;)
            return national_rank, position_rank, state_rank
        except AttributeError:
            return None, None, None


    def _get_status(self, player:str):
        try:
            status = player.find(&#34;div&#34;, class_ = &#34;status&#34;)
        except AttributeError:
            return None, None

        # if player is commited to team
        try: 
            team = status.find(&#34;a&#34;, class_ = &#34;img-link&#34;).find(&#34;img&#34;)[&#39;alt&#39;]
            return team, None
        except:
            pass

        # if player is not committed or almost committed
        team_helper = status.find(&#34;div&#34;, class_ = &#34;rankings-page__crystal-ball&#34;).find(&#34;div&#34;, class_ = &#34;cb-block&#34;)
        try:
            team = team_helper.find(&#34;img&#34;)[&#39;alt&#39;]
            percentage = team_helper.find(&#34;span&#34;, class_ = &#34;percentage&#34;).text.strip()
            return team, percentage
        
        except:
            return None, None
    @property
    def get_players(self):
        players = []
        for player in tqdm(self.html_players):
            p_dict = {}
            p_dict[&#39;primary_ranking&#39;], p_dict[&#39;other_ranking&#39;] = self._get_ranking(player)
            p_dict[&#39;recruit_link&#39;], p_dict[&#39;recruit_name&#39;], p_dict[&#39;recruit_location&#39;] = self._get_recruit(player)
            p_dict[&#39;position&#39;] = self._get_position(player)
            p_dict[&#39;metrics&#39;] = self._get_metrics(player)
            p_dict[&#39;national_rank&#39;], p_dict[&#39;position_rank&#39;], p_dict[&#39;state_rank&#39;] = self._get_ratings(player)
            p_dict[&#39;commited_team&#39;], p_dict[&#39;commited_team_percentage&#39;] = self._get_status(player)
            players.append(p_dict)
        # cache player list in class
        Players.players = players
        return players 

    @property
    def to_df(self):
        if Players.players is None:
            Players.players = self.get_players
        
        return pd.DataFrame.from_dict(Players.players)</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="recruits.ncaaf.player.Players.players"><code class="name">var <span class="ident">players</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="recruits.ncaaf.player.Players.get_players"><code class="name">var <span class="ident">get_players</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def get_players(self):
    players = []
    for player in tqdm(self.html_players):
        p_dict = {}
        p_dict[&#39;primary_ranking&#39;], p_dict[&#39;other_ranking&#39;] = self._get_ranking(player)
        p_dict[&#39;recruit_link&#39;], p_dict[&#39;recruit_name&#39;], p_dict[&#39;recruit_location&#39;] = self._get_recruit(player)
        p_dict[&#39;position&#39;] = self._get_position(player)
        p_dict[&#39;metrics&#39;] = self._get_metrics(player)
        p_dict[&#39;national_rank&#39;], p_dict[&#39;position_rank&#39;], p_dict[&#39;state_rank&#39;] = self._get_ratings(player)
        p_dict[&#39;commited_team&#39;], p_dict[&#39;commited_team_percentage&#39;] = self._get_status(player)
        players.append(p_dict)
    # cache player list in class
    Players.players = players
    return players </code></pre>
</details>
</dd>
<dt id="recruits.ncaaf.player.Players.to_df"><code class="name">var <span class="ident">to_df</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def to_df(self):
    if Players.players is None:
        Players.players = self.get_players
    
    return pd.DataFrame.from_dict(Players.players)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="recruits.ncaaf" href="index.html">recruits.ncaaf</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="recruits.ncaaf.player.Player" href="#recruits.ncaaf.player.Player">Player</a></code></h4>
<ul class="">
<li><code><a title="recruits.ncaaf.player.Player.player" href="#recruits.ncaaf.player.Player.player">player</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="recruits.ncaaf.player.Players" href="#recruits.ncaaf.player.Players">Players</a></code></h4>
<ul class="">
<li><code><a title="recruits.ncaaf.player.Players.get_players" href="#recruits.ncaaf.player.Players.get_players">get_players</a></code></li>
<li><code><a title="recruits.ncaaf.player.Players.players" href="#recruits.ncaaf.player.Players.players">players</a></code></li>
<li><code><a title="recruits.ncaaf.player.Players.to_df" href="#recruits.ncaaf.player.Players.to_df">to_df</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>